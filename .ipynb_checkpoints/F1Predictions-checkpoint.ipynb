{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Race Predictions\n",
    "### APC's Kaggle Project by Juan Carlos Soriano Valle (1493037)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a71014e204da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdescartes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from wordcloud import WordCloud\n",
    "import descartes\n",
    "import datetime\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from dateutil.relativedelta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/\"\n",
    "driversPath = \"drivers\"\n",
    "constructorsPath = \"constructors\"\n",
    "racesPath = \"races\"\n",
    "resultsPath = \"results\"\n",
    "seasonsPath = \"seasons\"\n",
    "circuitsPath = \"circuits\"\n",
    "qualifyingPath = \"qualifying\"\n",
    "driverStandingsPath = \"driver_standings\"\n",
    "constructorStandingsPath = \"constructor_standings\"\n",
    "constructorResultsPath = \"constructor_results\"\n",
    "statusPath = \"status\"\n",
    "lapTimesPath = \"lap_times\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statusDF = pd.read_csv(path+statusPath+\".csv\")\n",
    "\n",
    "print(statusDF.shape)\n",
    "print(\"Total status:\", statusDF.shape[0])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(statusDF.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driversDF = pd.read_csv(path+driversPath+\".csv\")\n",
    "\n",
    "print(driversDF.shape)\n",
    "print(\"Total drivers:\", driversDF.shape[0])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "driversDF.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values:\\n\",driversDF.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(driversDF.number.str.count(\"N\").sum())\n",
    "print(driversDF.number.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructorsDF = pd.read_csv(path+constructorsPath+\".csv\")\n",
    "\n",
    "print(constructorsDF.shape)\n",
    "print(\"Total Constructors:\", constructorsDF.shape[0])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "constructorsDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values:\\n\",constructorsDF.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "racesDF = pd.read_csv(path+racesPath+\".csv\")\n",
    "\n",
    "print(racesDF.shape)\n",
    "print(\"Total Races:\", racesDF.shape[0])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "racesDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values:\\n\",racesDF.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = []\n",
    "for season in np.array(racesDF.year.unique()):\n",
    "    rounds.append([season, list(racesDF[racesDF.year == season][\"round\"])])\n",
    "rounds.sort()\n",
    "\n",
    "countRounds = racesDF.groupby('year').round.max().reset_index()['round'].tolist()\n",
    "yearRounds = racesDF.groupby('year').round.max().reset_index()['year'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fig = plt.figure(figsize=(12,5))\n",
    "plt.title(\"nRaces per Season\")\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(yearRounds,countRounds)\n",
    "plt.show()\"\"\"\n",
    "\n",
    "fig_dims=(15,5)\n",
    "fig, ax = plt.subplots(figsize=fig_dims)\n",
    "sns.barplot(yearRounds,countRounds)\n",
    "plt.xlabel(\"Years\")\n",
    "plt.ylabel(\"nRaces\")\n",
    "plt.title(\"nRaces per Season\", fontsize=20)\n",
    "ax.set_yticks(range(23))\n",
    "\n",
    "xticks=ax.xaxis.get_major_ticks()\n",
    "for i in range(len(xticks)):\n",
    "    if i%2!=0:\n",
    "        xticks[i].set_visible(False)\n",
    "\n",
    "yticks=ax.yaxis.get_major_ticks()\n",
    "for i in range(len(yticks)):\n",
    "    if i%2!=0:\n",
    "        yticks[i].set_visible(False)\n",
    "\n",
    "ax.set_xticklabels(yearRounds,rotation=45);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDF = pd.read_csv(path+resultsPath+\".csv\")\n",
    "\n",
    "print(resultsDF.shape)\n",
    "print(\"Total Races:\", resultsDF.shape[0])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "resultsDF.head(22)\n",
    "\n",
    "years = []\n",
    "rounds = []\n",
    "circuits = []\n",
    "times = []\n",
    "for ids in resultsDF.raceId:\n",
    "    years.append(racesDF.loc[racesDF[\"raceId\"]==ids, \"year\"].iloc[0])\n",
    "    rounds.append(racesDF.loc[racesDF[\"raceId\"]==ids, \"round\"].iloc[0])\n",
    "    circuits.append(racesDF.loc[racesDF[\"raceId\"]==ids, \"circuitId\"].iloc[0])\n",
    "    \n",
    "for lapTimes in resultsDF.fastestLapTime:\n",
    "    x = lapTimes.split(\".\")\n",
    "    try:\n",
    "        dt_obj = time.strptime(lapTimes, \"%M:%S.%f\")\n",
    "        millitime = datetime.timedelta(hours=dt_obj.tm_hour,minutes=dt_obj.tm_min,seconds=dt_obj.tm_sec,milliseconds=int(x[1])).total_seconds()*1000\n",
    "        times.append(millitime)\n",
    "    except:\n",
    "        times.append(300000)\n",
    "resultsDF[\"year\"] = years\n",
    "resultsDF[\"round\"] = rounds\n",
    "resultsDF[\"circuitId\"] = circuits\n",
    "resultsDF[\"fastestLapMill\"] = times\n",
    "display(resultsDF.head(22))\n",
    "display(resultsDF.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values:\\n\",resultsDF.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status = resultsDF['statusId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statusFrame = status.to_frame()\n",
    "\n",
    "\n",
    "indexnames={}\n",
    "for idx in statusFrame.index:\n",
    "    name = statusDF.loc[statusDF[\"statusId\"]==idx, \"status\"].iloc[0]\n",
    "    indexnames[idx]=name\n",
    "statusDef=statusFrame.rename(index=indexnames)\n",
    "\n",
    "s=statusDef[\"statusId\"]\n",
    "otherS = s.groupby(np.where(s>=200,s.index,'other')).sum()#.plot.pie(figsize=(10, 10))\n",
    "otherS=otherS.sort_values(ascending=False)\n",
    "otherS.plot.pie(figsize=(10, 10))\n",
    "display(otherS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "winResults = resultsDF[resultsDF['position'] == \"1\"]\n",
    "winCount = winResults[\"driverId\"].value_counts()\n",
    "winCount = winCount.to_frame()\n",
    "#display(winCount)\n",
    "\n",
    "indexnames={}\n",
    "for idx in winCount.index:\n",
    "    name = driversDF.loc[driversDF[\"driverId\"]==idx, \"surname\"].iloc[0]\n",
    "    indexnames[idx]=name\n",
    "winCountDef=winCount.rename(index=indexnames)\n",
    "\n",
    "winCountDef.plot.pie(figsize=(10, 10), subplots=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#winCountDef.index\n",
    "wins = winResults['driverId'].tolist()\n",
    "#str1 = ''.join(wins)\n",
    "\n",
    "str2 = []\n",
    "\n",
    "for idx in range(len(wins)):\n",
    "    #print(str1[idx+1])\n",
    "    #print(driversDF[\"driverId\"]==int(str1[idx+1]))\n",
    "    name = driversDF.loc[driversDF[\"driverId\"]==int(wins[idx]), \"surname\"].iloc[0]\n",
    "    str2.append(name)\n",
    "\n",
    "str2=str(str2)\n",
    "str2 = str2.replace(\",\", \"\")\n",
    "str2 = str2.replace(\"'\", \"\")\n",
    "str2 = str2.replace(\" \", \"\\n\")\n",
    "\n",
    "#print(str2)\n",
    "wordcloud = WordCloud(width=1600, height=800, margin=0,collocations=False, colormap=\"hot\").generate(str(str2))\n",
    "\"\"\"plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show()\"\"\"\n",
    "\n",
    "\n",
    "plt.figure( figsize=(20,10), facecolor='k')\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.savefig('cloudword.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonsDF = pd.read_csv(path+seasonsPath+\".csv\")\n",
    "\n",
    "print(seasonsDF.shape)\n",
    "print(\"Total Seasons:\", seasonsDF.shape[0])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(seasonsDF.head(5))\n",
    "display(seasonsDF.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values:\\n\",seasonsDF.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuitsDF = pd.read_csv(path+circuitsPath+\".csv\")\n",
    "\n",
    "print(circuitsDF.shape)\n",
    "print(\"Total Circuits:\", circuitsDF.shape[0])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(circuitsDF.head(6))\n",
    "display(circuitsDF.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values:\\n\",circuitsDF.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifyingDF = pd.read_csv(path+qualifyingPath+\".csv\")\n",
    "\n",
    "print(qualifyingDF.shape)\n",
    "print(\"Total Qualifying:\", qualifyingDF.shape[0])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(qualifyingDF.head(22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values:\\n\",qualifyingDF.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver Standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driverStandingsDF = pd.read_csv(path+driverStandingsPath+\".csv\")\n",
    "\n",
    "print(driverStandingsDF.shape)\n",
    "print(\"Total Driver Standings:\", driverStandingsDF.shape[0])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(driverStandingsDF.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values:\\n\",driverStandingsDF.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructor Standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructorStandingsDF = pd.read_csv(path+constructorStandingsPath+\".csv\")\n",
    "\n",
    "print(constructorStandingsDF.shape)\n",
    "print(\"Total Constructor Standings:\", constructorStandingsDF.shape[0])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(constructorStandingsDF.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values:\\n\",constructorStandingsDF.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructor Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructorResultsDF = pd.read_csv(path+constructorResultsPath+\".csv\")\n",
    "\n",
    "print(constructorResultsDF.shape)\n",
    "print(\"Total Constructor Results:\", constructorResultsDF.shape[0])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(constructorResultsDF.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values:\\n\",constructorResultsDF.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(constructorResultsDF.status.str.count(\"N\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "constructorResultsDF.loc[:,\"status\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructorResultsDF['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lap Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lapTimesDF = pd.read_csv(path+lapTimesPath+\".csv\")\n",
    "\n",
    "print(lapTimesDF.shape)\n",
    "print(\"Total Lap Times:\", lapTimesDF.shape[0])\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(lapTimesDF.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,9))\n",
    "_ = sns.lineplot(x=\"lap\", y=\"position\", hue=\"driverId\", data=lapTimesDF[lapTimesDF[\"raceId\"]==973], palette=\"Paired\", legend=\"full\")\n",
    "_.set_yticks(range(19))\n",
    "_.set_xticks(range(67))\n",
    "_.yaxis.set_ticks_position(\"both\")\n",
    "\n",
    "driversNum=lapTimesDF[lapTimesDF[\"raceId\"]==973][\"driverId\"].unique()\n",
    "driversNum.sort()\n",
    "names = []\n",
    "\n",
    "for num in driversNum:\n",
    "    names.append(driversDF.loc[driversDF[\"driverId\"]==num, \"code\"].iloc[0])\n",
    "\n",
    "#race{year;name}\n",
    "race={}\n",
    "race[\"year\"]=racesDF.loc[racesDF[\"raceId\"]==973, \"year\"].iloc[0]\n",
    "race[\"name\"]=racesDF.loc[racesDF[\"raceId\"]==973, \"name\"].iloc[0]\n",
    "plt.title(str(race[\"year\"])+ \" \" + str(race[\"name\"]), fontsize=20)\n",
    "plt.legend(title=\"Drivers\",loc='best',labels=names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,9))\n",
    "\"\"\"valencia = lapTimesDF[lapTimesDF[\"raceId\"]==867]\n",
    "alonso = valencia[valencia[\"driverId\"]==4]\n",
    "display(alonso)\n",
    "\"\"\"\n",
    "_ = sns.lineplot(x=\"lap\", y=\"position\", hue=\"driverId\", data=lapTimesDF[lapTimesDF[\"raceId\"]==867], palette=\"Paired\", legend=\"full\")\n",
    "_.set_yticks(range(25))\n",
    "_.set_xticks(range(58))\n",
    "_.yaxis.set_ticks_position(\"both\")\n",
    "\n",
    "driversNum=lapTimesDF[lapTimesDF[\"raceId\"]==867][\"driverId\"].unique()\n",
    "driversNum.sort()\n",
    "names = []\n",
    "\n",
    "for num in driversNum:\n",
    "    names.append(driversDF.loc[driversDF[\"driverId\"]==num, \"code\"].iloc[0])\n",
    "\n",
    "#race{year;name}\n",
    "race={}\n",
    "race[\"year\"]=racesDF.loc[racesDF[\"raceId\"]==867, \"year\"].iloc[0]\n",
    "race[\"name\"]=racesDF.loc[racesDF[\"raceId\"]==867, \"name\"].iloc[0]\n",
    "plt.title(str(race[\"year\"])+ \" \" + str(race[\"name\"]), fontsize=20)\n",
    "plt.legend(title=\"Drivers\",loc='best',labels=names);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "crs={\"init\":\"epsg:4326\"}\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "races=racesDF.loc[racesDF[\"year\"]==1950]\n",
    "races2019=racesDF.loc[racesDF[\"year\"]==2019]\n",
    "z=np.random.rand(100,100)\n",
    "\n",
    "lat=[]\n",
    "lon=[]\n",
    "\n",
    "lat1=[]\n",
    "lon1=[]\n",
    "\n",
    "\n",
    "for race in races[\"circuitId\"]:\n",
    "    lat.append(circuitsDF.loc[circuitsDF[\"circuitId\"]==race, \"lat\"].iloc[0])\n",
    "    lon.append(circuitsDF.loc[circuitsDF[\"circuitId\"]==race, \"lng\"].iloc[0])\n",
    "\n",
    "races.insert(8,\"lat\", lat, True)\n",
    "races.insert(9,\"lng\", lon, True)\n",
    "#display(races)\n",
    "points1950 = [Point(xy) for xy in zip( races[\"lng\"], races[\"lat\"] )]\n",
    "geo1950 = gpd.GeoDataFrame(races, geometry=points1950, crs=crs)\n",
    "#display(geo1950)\n",
    "\n",
    "\n",
    "for race in races2019[\"circuitId\"]:\n",
    "    lat1.append(circuitsDF.loc[circuitsDF[\"circuitId\"]==race, \"lat\"].iloc[0])\n",
    "    lon1.append(circuitsDF.loc[circuitsDF[\"circuitId\"]==race, \"lng\"].iloc[0])\n",
    "\n",
    "races2019.insert(8,\"lat\", lat1, True)\n",
    "races2019.insert(9,\"lng\", lon1, True)\n",
    "points2019 = [Point(xy) for xy in zip( races2019[\"lng\"], races2019[\"lat\"] )]\n",
    "geo2019 = gpd.GeoDataFrame(races2019, geometry=points2019, crs=crs)\n",
    "\n",
    "\n",
    "\n",
    "fig,(ax1, ax2) = plt.subplots(ncols=2)\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    if ax == ax1:\n",
    "        world.plot(ax=ax, alpha=0.4)\n",
    "        geo1950.plot(ax=ax, markersize=40, marker=\"o\",cmap='Dark2')\n",
    "        ax.set_ylim([-5,75])\n",
    "        ax.set_xlim([-120,50])\n",
    "        ax.set_title(\"Race Locations on First Championship Season (1950)\", fontsize=15)\n",
    "    else:\n",
    "        world.plot(ax=ax, alpha=0.3)\n",
    "        geo2019.plot(ax=ax, markersize=40, marker=\"o\", cmap=\"tab10\")\n",
    "        ax.set_ylim([-50,60])\n",
    "        ax.set_xlim([-140,160])\n",
    "        ax.set_title(\"Race Locations on Last Completed Championship Season (2019)\", fontsize=15)\n",
    "\n",
    "asp = np.diff(ax2.get_xlim())[0] / np.diff(ax2.get_ylim())[0]\n",
    "ax2.set_aspect(asp*0.7)\n",
    "fig.set_size_inches(20,8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importancia de la pole\n",
    "perCircuits = {}\n",
    "circuits = []\n",
    "poleResults = resultsDF[resultsDF[\"grid\"]==1]\n",
    "\n",
    "for race in poleResults.raceId:\n",
    "    circuit = racesDF.loc[racesDF[\"raceId\"]==race, \"circuitId\"].iloc[0]\n",
    "    circuits.append(circuit)\n",
    "\n",
    "poleResults[\"circuitId\"]=circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=[]\n",
    "names={}\n",
    "\n",
    "for index, row in poleResults.iterrows():\n",
    "    delta.append(row.grid == row.positionOrder)\n",
    "\n",
    "poleResults[\"poleWin\"]=delta\n",
    "\n",
    "#display(poleResults)\n",
    "\n",
    "\n",
    "#print(poleResults.circuitId.unique())\n",
    "\n",
    "for circuits in poleResults.circuitId.unique():\n",
    "    counter=0\n",
    "    perfect=0\n",
    "    circuitResults = poleResults[poleResults[\"circuitId\"]==circuits]\n",
    "    for index, row in circuitResults.iterrows():\n",
    "        if row.poleWin:\n",
    "            perfect+=1\n",
    "        counter+=1\n",
    "    perCircuits[circuits]=perfect/counter\n",
    "\n",
    "\n",
    "for key in perCircuits.keys():\n",
    "    name = circuitsDF.loc[circuitsDF[\"circuitId\"]==key,\"circuitRef\"].iloc[0]\n",
    "    names[name]=perCircuits[key]\n",
    "\n",
    "\n",
    "sortedNames = {}\n",
    "sortedKeys = sorted(names, key=names.get, reverse=True)\n",
    "for w in sortedKeys:\n",
    "    sortedNames[w] = names[w]\n",
    "    \n",
    "\n",
    "sortedNames.pop(\"pedralbes\")\n",
    "sortedNames.pop(\"pescara\")\n",
    "sortedNames.pop(\"ain-diab\")\n",
    "sortedNames.pop(\"sebring\")\n",
    "sortedNames.pop(\"zeltweg\")\n",
    "sortedNames.pop(\"lemans\")\n",
    "sortedNames.pop(\"tremblant\")\n",
    "sortedNames.pop(\"montjuic\")\n",
    "sortedNames.pop(\"las_vegas\")\n",
    "sortedNames.pop(\"dallas\")\n",
    "sortedNames.pop(\"donington\")\n",
    "sortedNames.pop(\"okayama\")\n",
    "sortedNames.pop(\"riverside\")\n",
    "sortedNames.pop(\"avus\")\n",
    "sortedNames.pop(\"monsanto\")\n",
    "sortedNames.pop(\"buddh\")\n",
    "sortedNames.pop(\"mugello\")\n",
    "sortedNames.pop(\"portimao\")\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.bar(range(len(sortedNames)), list(sortedNames.values()), align=\"center\")\n",
    "plt.xticks(range(len(sortedNames)), list(sortedNames.keys()),rotation=90)\n",
    "plt.title(\"Correlation Pole Position/Win per Circuit\", fontsize=(20))\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardado en ./data/weatherInfo.csv\n",
    "\"\"\"from selenium import webdriver\n",
    "\n",
    "weather = racesDF.iloc[:,[1,2,3]]\n",
    "state = []\n",
    "\n",
    "for link in racesDF.url:\n",
    "    try:\n",
    "        df = pd.read_html(link)[0]\n",
    "        if \"Weather\" in list(df.iloc[:,0]):\n",
    "            idx = list(df.iloc[:,0]).index(\"Weather\")\n",
    "            state.append(df.iloc[idx,1])\n",
    "        else:\n",
    "            df = pd.read_html(link)[1]\n",
    "            if \"Weather\" in list(df.iloc[:,0]):\n",
    "                idx = list(df.iloc[:,0]).index(\"Weather\")\n",
    "                state.append(df.iloc[idx,1])\n",
    "            else:\n",
    "                df = pd.read_html(link)[2]\n",
    "                if \"Weather\" in list(df.iloc[:,0]):\n",
    "                    idx = list(df.iloc[:,0]).index(\"Weather\")\n",
    "                    state.append(df.iloc[idx,1])\n",
    "                else:\n",
    "                    df = pd.read_html(link)[3]\n",
    "                    if \"Weather\" in list(df.iloc[:,0]):\n",
    "                        idx = list(df.iloc[:,0]).index(\"Weather\")\n",
    "                        state.append(df.iloc[idx,1])\n",
    "                    else:\n",
    "                        explorer = webdriver.Chrome()\n",
    "                        explorer.get(link)\n",
    "                        \n",
    "                        lang = explorer.find_element_by_link_text(\"Italiano\")\n",
    "                        lang.click()\n",
    "                        \n",
    "                        itaWeather = explorer.find_element_by_xpath('//*[@id=\"mw-content-text\"]/div/table[1]/tbody/tr[9]/td').text\n",
    "                        state.append(itaWeather)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    \n",
    "    except:\n",
    "        state.append(\"not found\")\n",
    "        \n",
    "weather[\"weather\"] = state\n",
    "\n",
    "weatherDict = {'weather_warm': ['soleggiato', 'clear', 'warm', 'hot', 'sunny', 'fine', 'mild', 'sereno'],\n",
    "               'weather_cold': ['cold', 'fresh', 'chilly', 'cool'],\n",
    "               'weather_dry': ['dry', 'asciutto'],\n",
    "               'weather_wet': ['showers', 'wet', 'rain', 'pioggia', 'damp', 'thunderstorms', 'rainy'],\n",
    "               'weather_cloudy': ['overcast', 'nuvoloso', 'clouds', 'cloudy', 'grey', 'coperto']}\n",
    "\n",
    "weatherDF = pd.DataFrame(columns = weatherDict.keys())\n",
    "for col in weatherDF:\n",
    "    weatherDF[col] = weather[\"weather\"].map(lambda x: 1 if any(i in weatherDict[col] for i in x.lower().split()) else 0)\n",
    "    \n",
    "weatherInfo = pd.concat([weather, weatherDF], axis = 1)\"\"\"\n",
    "\n",
    "weatherInfo = pd.read_csv(\"./data/weatherInfo.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(weatherInfo)\n",
    "weatherInfo.to_csv(\"./data/weatherInfo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(racesDF, weatherInfo, how=\"inner\", on=[\"year\", \"round\", \"circuitId\"]).drop([\"weather\", \"time\", \"url\"], axis=1)\n",
    "#df1\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDriversDF = pd.merge(resultsDF,driversDF,how=\"left\", on=[\"driverId\"]).drop([\"code\", \"forename\", \"surname\", \"url\", \"number_y\", \"number_x\"], axis=1)\n",
    "resultsDriversDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df1, resultsDriversDF, how=\"inner\", on=[\"year\", \"round\", \"circuitId\", \"raceId\"]).drop([\"points\", \"statusId\", \"position\", \"positionText\", \"time\", \"rank\", \"fastestLapSpeed\"], axis=1)\n",
    "print(df2.shape)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driverStandingsDF.rename(columns={\"position\":\"driverStandingPosition\", \"positionText\":\"driverStandingPositionText\"}, inplace=True)\n",
    "df3 = pd.merge(df2, driverStandingsDF, how=\"left\", on=[\"raceId\",\"driverId\"]).drop([\"driverStandingsId\", \"driverStandingPositionText\",\"fastestLapTime\",\"fastestLap\"], axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructors = []\n",
    "for constructor in df3.constructorId:\n",
    "    constructors.append(constructorsDF.loc[constructorsDF[\"constructorId\"]==constructor, \"constructorRef\"].iloc[0])\n",
    "df3[\"constructor\"] = constructors\n",
    "df3 = df3.drop([\"constructorId\"], axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructorStandingsFinalDF = constructorStandingsDF\n",
    "\n",
    "years = []\n",
    "rounds = []\n",
    "constructors = []\n",
    "for ids in constructorStandingsFinalDF.raceId:\n",
    "    years.append(racesDF.loc[racesDF[\"raceId\"]==ids, \"year\"].iloc[0])\n",
    "    rounds.append(racesDF.loc[racesDF[\"raceId\"]==ids, \"round\"].iloc[0])\n",
    "for ids in constructorStandingsFinalDF.constructorId:\n",
    "    constructors.append(constructorsDF.loc[constructorsDF[\"constructorId\"]==ids, \"constructorRef\"].iloc[0])\n",
    "    \n",
    "constructorStandingsFinalDF[\"year\"] = years\n",
    "constructorStandingsFinalDF[\"round\"] = rounds\n",
    "constructorStandingsFinalDF[\"constructor\"] = constructors\n",
    "\n",
    "constructorStandingsFinalDF = constructorStandingsFinalDF.drop([\"constructorStandingsId\", \"raceId\", \"constructorId\", \"positionText\"], axis = 1)\n",
    "constructorStandingsFinalDF = constructorStandingsFinalDF.rename(columns={\"points\": \"constructorPoints\", \"wins\": \"constructorWins\", \"position\":\"constructorPosition\"})\n",
    "\n",
    "constructorStandingsFinalDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.merge(df3, constructorStandingsFinalDF, how=\"left\", on=[\"year\", \"round\", \"constructor\"])\n",
    "print(df4.shape)\n",
    "\n",
    "df4.grid = df4.grid.replace({0: 99})\n",
    "\n",
    "df4.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qualyTime = []\n",
    "for index, row in qualifyingDF.iterrows():\n",
    "    if row.q3 != str(r\"\\N\"):\n",
    "        qualyTime.append(row.q3)\n",
    "    else:\n",
    "        if row.q2 != str(r\"\\N\"):\n",
    "            qualyTime.append(row.q2)\n",
    "        else:\n",
    "            if row.q1 != str(r\"\\N\"):\n",
    "                qualyTime.append(row.q1)\n",
    "            else:\n",
    "                qualyTime.append(0)\n",
    "qualifyingFinalDF = qualifyingDF\n",
    "qualifyingFinalDF[\"qualyTime\"] = qualyTime\n",
    "qualifyingFinalDF=qualifyingFinalDF.drop([\"q1\", \"q2\", \"q3\", \"number\", \"qualifyId\"], axis=1)\n",
    "qualifyingFinalDF = qualifyingFinalDF.rename(columns={\"position\":\"grid\"})\n",
    "\n",
    "rounds = []\n",
    "years = []\n",
    "for race in qualifyingFinalDF.raceId:\n",
    "    rounds.append(racesDF.loc[racesDF[\"raceId\"]==race, \"round\"].iloc[0])\n",
    "    years.append(racesDF.loc[racesDF[\"raceId\"]==race, \"year\"].iloc[0])\n",
    "    \n",
    "\n",
    "qualifyingFinalDF = qualifyingFinalDF.drop([\"raceId\"], axis=1)\n",
    "qualifyingFinalDF[\"year\"] = years\n",
    "qualifyingFinalDF[\"round\"] = rounds\n",
    "print(qualifyingDF.shape)\n",
    "print(qualifyingFinalDF.shape)\n",
    "qualifyingFinalDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.tail(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "finalDF = pd.merge(df4, qualifyingFinalDF, how=\"left\", on=[\"year\", \"round\", \"driverId\"]).drop([\"constructorId\", \"grid_y\"], axis=1)\n",
    "#IMPORTANTE, HAY 2 GRIDS AL HACER EL MERGE, Y SON LAS POSICIONES \"RAW\" DE LA CLASIFICACION DEL SABADO, MIENTRAS QUE EL X ES EL RESULTADO DE LAS CLASIFICACIONES+PENALIZACIONES\n",
    "finalDF = finalDF.rename(columns={\"grid_x\":\"grid\"})\n",
    "print(finalDF.shape)\n",
    "finalDF.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minValue = finalDF['year'].min()\n",
    "maxValue = finalDF['year'].max()\n",
    "print(minValue)\n",
    "print(maxValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values:\\n\",finalDF.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age on every race for drivers\n",
    "finalDF[\"date\"] = pd.to_datetime(finalDF.date)\n",
    "finalDF[\"dob\"] = pd.to_datetime(finalDF.dob)\n",
    "finalDF[\"driverAge\"] = finalDF.apply(lambda x: relativedelta(x[\"date\"],x[\"dob\"]).years, axis=1)\n",
    "finalDF.drop([\"date\", \"dob\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Antes de la conversiÃ³n:\", finalDF.shape)\n",
    "\n",
    "\n",
    "\n",
    "for col in [\"points\", \"driverStandingPosition\", \"wins\", \"constructorPoints\", \"constructorPosition\", \"constructorWins\"]:\n",
    "    finalDF[col].fillna(0, inplace = True)\n",
    "    finalDF[col] = finalDF[col].map(lambda x: int(x))\n",
    "    \n",
    "finalDF[\"qualyTime\"] = finalDF[\"qualyTime\"].fillna(value=0)\n",
    "finalDF.loc[(finalDF.qualyTime == 0), \"qualyTime\"] = \"4:59.999\"\n",
    "finalDF.loc[(finalDF.milliseconds == r\"\\N\"), \"milliseconds\"] = 99999999\n",
    "    \n",
    "finalDF.dropna(inplace = True)\n",
    "print(\"Despues de la conversion:\", finalDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"missing values:\\n\",finalDF.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qualyDiff\n",
    "finalDF[\"qualyTime\"] = finalDF.qualyTime.map(lambda x: 0 if str(x) == \"00.000\" else(float(str(x).split(\":\")[1]) + (60 * float(str(x).split(\":\")[0])) if x!= 0 else 0))\n",
    "finalDF = finalDF[finalDF[\"qualyTime\"] != 0]\n",
    "finalDF.sort_values([\"year\", \"round\", \"grid\"], inplace = True)\n",
    "finalDF[\"qualyDiff\"] = finalDF.groupby([\"year\", \"round\"]).qualyTime.diff()\n",
    "finalDF[\"qualyTime\"] = finalDF.groupby([\"year\", \"round\"]).qualyDiff.cumsum().fillna(0)\n",
    "finalDF.drop(\"qualyDiff\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = finalDF[\"grid\"].value_counts() \n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quitamos todas las filas de turkish gp porque no tienen los datos de wins bien definidos\n",
    "finalDF.drop(finalDF.tail(20).index,inplace=True) # drop last n rows\n",
    "finalDF.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del finalDF['circuitId']\n",
    "del finalDF['raceId']\n",
    "del finalDF['resultId']\n",
    "finalDF.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertir a dummies -> strings a atributos y 0/1\n",
    "# name -> circuit name\n",
    "dummies = pd.get_dummies(finalDF, columns = [\"name\", \"nationality\", \"constructor\"])\n",
    "\n",
    "indexNames = dummies[dummies[\"year\"] < 1989].index\n",
    "dummies.drop(indexNames, inplace=True)\n",
    "\n",
    "for col in dummies.columns:\n",
    "    if \"name\" in col and dummies[col].sum() < 60:\n",
    "        dummies.drop(col, axis=1, inplace=True)\n",
    "    elif \"nationality\" in col and dummies[col].sum() < 60:\n",
    "        dummies.drop(col, axis=1, inplace=True)\n",
    "    elif \"constructor\" in col and dummies[col].sum() < 80:\n",
    "        dummies.drop(col, axis=1, inplace=True)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexNames = dummies[dummies[\"year\"] < 1989].index\n",
    "dummies.drop(indexNames, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies['milliseconds']=dummies.milliseconds.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies.to_csv(\"./data/finalDF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1DF = pd.read_csv(\"./data/finalDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression\n",
    "predictingYear = 1993\n",
    "\n",
    "\n",
    "regressionDF = f1DF.copy()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "trainSet = regressionDF[regressionDF.year != int(predictingYear)]\n",
    "xTrain = trainSet.drop([\"driverRef\", \"positionOrder\"], axis=1)\n",
    "yTrain = trainSet.positionOrder\n",
    "\n",
    "xTrain = pd.DataFrame(scaler.fit_transform(xTrain), columns = xTrain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_dict = {\"model\":[], \"params\":[], \"score\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scoring functions\n",
    "def scoreRegression(model, predictYear):\n",
    "    score = 0\n",
    "    driversList = []\n",
    "    \n",
    "    for race in f1DF[f1DF.year == int(predictYear)][\"round\"].unique():\n",
    "        \n",
    "        #train/test\n",
    "        \n",
    "        testDF = f1DF[(f1DF.year == int(predictYear)) & (f1DF[\"round\"] == race)]\n",
    "        #df.loc[df['B'] == 3, 'A'].iloc[0]\n",
    "        driversList = f1DF[(f1DF.year == int(predictYear)) & (f1DF[\"round\"] == race)][\"driverRef\"].tolist()\n",
    "        xTest = testDF.drop([\"driverRef\", \"positionOrder\"], axis=1)\n",
    "        yTest = testDF.positionOrder\n",
    "        \n",
    "        #scaler\n",
    "        xTest = pd.DataFrame(scaler.transform(xTest), columns = xTest.columns)\n",
    "        \n",
    "        #predictions\n",
    "        predictionDF = pd.DataFrame(model.predict(xTest), columns = [\"results\"])\n",
    "        predictionDF[\"driver\"] = driversList\n",
    "        predictionDF[\"positionOrder\"] = yTest.reset_index(drop=True)\n",
    "        predictionDF[\"real\"] = predictionDF.positionOrder.map(lambda x: 1 if x == 1 else 0)\n",
    "        predictionDF.sort_values(\"results\", ascending = True, inplace = True)\n",
    "        predictionDF.reset_index(inplace = True, drop = True)\n",
    "        predictionDF[\"predicted\"] = predictionDF.index\n",
    "        predictionDF[\"predicted\"] = predictionDF.predicted.map(lambda x:1 if x== 0 else 0)\n",
    "        \n",
    "        score += precision_score(predictionDF.real, predictionDF.predicted)\n",
    "        \n",
    "        display(predictionDF)\n",
    "        \n",
    "    totalScore = score / f1DF[f1DF.year == int(predictYear)][\"round\"].unique().max()\n",
    "    \n",
    "    return totalScore\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#linear regression\n",
    "\n",
    "params={\"fit_intercept\" : [\"True\", \"False\"]}\n",
    "\n",
    "for fit_intercept in params[\"fit_intercept\"]:\n",
    "    model_params = (fit_intercept)\n",
    "    model = LinearRegression(fit_intercept = fit_intercept)\n",
    "    model.fit(xTrain, yTrain)\n",
    "    \n",
    "    #print(model.score(xTrain, yTrain))\n",
    "    \n",
    "    modelScore = scoreRegression(model, predictingYear)\n",
    "    \n",
    "    comparison_dict[\"model\"].append(\"linear_regression\")\n",
    "    comparison_dict[\"params\"].append(model_params)\n",
    "    comparison_dict[\"score\"].append(modelScore)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "comparison_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest regressor\n",
    "#n_estimators, max_features, max_depth\n",
    "params={\"max_features\": [\"auto\", 0.5, 0.9],\n",
    "        \"n_estimators\": [100, 500, 1000],\n",
    "        \"max_depth\": [5, 10, 20]}\n",
    "\n",
    "for feature in params[\"max_features\"]:\n",
    "    for estimator in params[\"n_estimators\"]:\n",
    "        for depth in params[\"max_depth\"]:\n",
    "            model_params = (feature, estimator, depth)\n",
    "            model = RandomForestRegressor(criterion = \"mse\", max_features = feature, n_estimators=estimator, max_depth=depth, random_state=42)\n",
    "            model.fit(xTrain, yTrain)\n",
    "            \n",
    "            modelScore = score_regression(model, predictingYear)\n",
    "            \n",
    "            comparison_dict[\"model\"].append(\"random_forest_regressor\")\n",
    "            comparison_dict[\"params\"].append(model_params)\n",
    "            comparison_dict[\"score\"].append(modelScore)\n",
    "            \n",
    "comparison_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
